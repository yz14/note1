\begin{abstract}
These notes aim to give a gentle introduction to some important topics in
continuous optimization. The focus is on methods that arise in machine learning
and modern data analysis, highlighting concerns about complexity, robustness,
and implementation in these domains. 

Each section in these notes roughly corresponds to an $80$ minutes lecture,
adding up to one semester course.  Numerous available ipython notebooks augment
the theoretical developments, linked to from the text and available on this web
page:

\begin{center}
{\Large \url{https://ee227c.github.io/}.}
\end{center}

These notes came out of the course \emph{EE227C: Convex Optimization and
Approximation}, taught at UC Berkeley in Spring, 2018.
\end{abstract}
